import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List
import os

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ø§Ø¦Ù…Ø© Stop Words
# -----------------------------
ARABIC_STOP_WORDS = {
    "Ùˆ", "ÙÙŠ", "Ù…Ù†", "Ø¥Ù„Ù‰", "Ø¹Ù†", "Ø¹Ù„Ù‰", "Ø¨", "Ù„", "Ø§", "Ø£Ùˆ", "Ø£Ù†", "Ø¥Ø°Ø§",
    "Ù…Ø§", "Ù‡Ø°Ø§", "Ù‡Ø°Ù‡", "Ø°Ù„Ùƒ", "ØªÙ„Ùƒ", "ÙƒØ§Ù†", "Ù‚Ø¯", "Ø§Ù„Ø°ÙŠ", "Ø§Ù„ØªÙŠ", "Ù‡Ùˆ", "Ù‡ÙŠ",
    "Ù", "Ùƒ", "Ø§Ù‰"
}

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = str(text).lower()
    text = text.replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡")
    text = text.replace("Ù€", "")
    text = re.sub(r"[Ù‹ÙŒÙÙÙÙ]", "", text)
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def light_stem(word: str) -> str:
    suffixes = ["ÙŠØ©", "ÙŠ", "ÙˆÙ†", "Ø§Øª", "Ø§Ù†", "ÙŠÙ†", "Ù‡"]
    for suf in suffixes:
        if word.endswith(suf) and len(word) > len(suf) + 2:
            word = word[:-len(suf)]
            break
    if word.startswith("Ø§Ù„") and len(word) > 3:
        word = word[2:]
    return word if word else ""

# -----------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø«
# -----------------------------
async def send_search_suggestions(update, context: ContextTypes.DEFAULT_TYPE, query: str, conn):
    """
    ØªØ¹Ø±Ø¶ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ø¯ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©
    """
    normalized_query = normalize_text(query)
    query_words = normalized_query.split()
    stemmed_query = [light_stem(w) for w in query_words if w not in ARABIC_STOP_WORDS]

    if not stemmed_query:
        await update.message.reply_text("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ø¨Ø­Ø«.")
        return

    # Ø¥Ù†Ø´Ø§Ø¡ tsquery Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OR Ù„Ù„Ø¬Ø°ÙˆØ±
    ts_query = ' | '.join(stemmed_query)

    try:
        results = await conn.fetch(f"""
            SELECT id, file_id, file_name, uploaded_at
            FROM books
            WHERE to_tsvector('arabic', file_name) @@ to_tsquery('arabic', $1)
            ORDER BY ts_rank(to_tsvector('arabic', file_name), to_tsquery('arabic', $1)) DESC
            LIMIT 10;
        """, ts_query)
    except Exception as e:
        await update.message.reply_text(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ø¨Ø­Ø«: {e}")
        return

    if not results:
        await update.message.reply_text("âŒ Ù„Ù„Ø£Ø³ÙØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø©.")
        return

    # Ø¨Ù†Ø§Ø¡ Ù„ÙˆØ­Ø© Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ù„Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
    keyboard = []
    for b in results:
        if not b.get("file_name") or not b.get("file_id"):
            continue
        key = hashlib.md5(b["file_id"].encode()).hexdigest()[:16]
        context.bot_data[f"file_{key}"] = b["file_id"]
        keyboard.append([InlineKeyboardButton(f"{b['file_name']}", callback_data=f"file:{key}")])

    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(
        f"ğŸ” Ù„Ù… Ù†Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ù‹Ø§ Ù„Ø¨Ø­Ø«Ùƒ '{query}' Ù„ÙƒÙ† Ø¥Ù„ÙŠÙƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª:",
        reply_markup=reply_markup
        )
