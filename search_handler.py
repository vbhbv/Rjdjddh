import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List, Dict, Any
import os
import math
from collections import Counter

BOOKS_PER_PAGE = 10

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±Ù
# -----------------------------

try:
    ADMIN_USER_ID = int(os.getenv("ADMIN_ID", "0"))  # Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø´Ø±Ù
except ValueError:
    ADMIN_USER_ID = 0
    print("âš ï¸ ADMIN_ID environment variable is not valid.")

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------

def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = text.lower()
    text = text.replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ")
    text = text.replace("Ù‡", "Ø©")
    return text

def remove_common_words(text: str) -> str:
    if not text:
        return ""
    for word in ["ÙƒØªØ§Ø¨", "Ø±ÙˆØ§ÙŠØ©", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"]:
        text = text.replace(word, "")
    return text.strip()

def extract_keywords(text: str) -> List[str]:
    if not text:
        return []
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    return [w for w in words if len(w) >= 3]

# -----------------------------
# TF-IDF + Cosine Similarity
# -----------------------------

def tokenize(text: str):
    return extract_keywords(normalize_text(remove_common_words(text)))

def compute_tf(words):
    count = Counter(words)
    total = len(words) or 1
    return {w: count[w] / total for w in count}

def compute_idf(documents):
    N = len(documents)
    idf = {}
    for doc in documents:
        for term in set(doc):
            idf[term] = idf.get(term, 0) + 1
    return {term: math.log(N / freq) for term, freq in idf.items()}

def compute_tfidf(words, idf):
    tf = compute_tf(words)
    return {term: tf.get(term, 0) * idf.get(term, 0) for term in idf}

def cosine_similarity(vec1, vec2):
    dot = sum(vec1.get(k, 0) * vec2.get(k, 0) for k in vec1)
    mag1 = math.sqrt(sum(v * v for v in vec1.values()))
    mag2 = math.sqrt(sum(v * v for v in vec2.values()))
    if mag1 == 0 or mag2 == 0:
        return 0
    return dot / (mag1 * mag2)

# -----------------------------
# Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù
# -----------------------------

async def notify_admin_search(context, username: str, query: str, found: bool):
    if ADMIN_USER_ID == 0:
        return

    bot = context.bot
    status_text = "âœ… Ù†ØªØ§Ø¦Ø¬" if found else "âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬"
    username_text = f"@{username}" if username else "(Ø¨Ø¯ÙˆÙ† ÙŠÙˆØ²Ø±)"

    message = (
        f"ğŸ”” Ù‚Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username_text} Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†:\n"
        f"`{query}`\nØ§Ù„Ø­Ø§Ù„Ø©: {status_text}"
    )
    try:
        await bot.send_message(ADMIN_USER_ID, message, parse_mode='Markdown')
    except:
        pass

# -----------------------------
# Ø¥Ø±Ø³Ø§Ù„ ØµÙØ­Ø§Øª Ø§Ù„ÙƒØªØ¨
# -----------------------------

async def send_books_page(update, context):
    books = context.user_data.get("search_results", [])
    page = context.user_data.get("current_page", 0)
    stage = context.user_data.get("search_stage", "")

    total_pages = max(1, (len(books) - 1) // BOOKS_PER_PAGE + 1)

    start = page * BOOKS_PER_PAGE
    end = start + BOOKS_PER_PAGE
    current_books = books[start:end]

    text = (
        f"ğŸ“š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({len(books)} ÙƒØªØ§Ø¨)\n"
        f"{stage}\n"
        f"Ø§Ù„ØµÙØ­Ø© {page + 1} Ù…Ù† {total_pages}\n\n"
    )

    keyboard = []

    for b in current_books:
        key = hashlib.md5(b["file_id"].encode()).hexdigest()[:16]
        context.bot_data[f"file_{key}"] = b["file_id"]
        keyboard.append([
            InlineKeyboardButton(f"ğŸ“˜ {b['file_name']}", callback_data=f"file:{key}")
        ])

    nav = []
    if page > 0:
        nav.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data="prev_page"))
    if end < len(books):
        nav.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data="next_page"))

    if nav:
        keyboard.append(nav)

    markup = InlineKeyboardMarkup(keyboard)

    if update.message:
        await update.message.reply_text(text, reply_markup=markup)
    else:
        await update.callback_query.message.edit_text(text, reply_markup=markup)

# -----------------------------
# Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯ (TF-IDF ÙÙ‚Ø·)
# -----------------------------

async def search_books(update, context):
    if update.effective_chat.type != "private":
        return

    query = update.message.text.strip()
    if not query:
        return

    conn = context.bot_data.get("db_conn")
    if not conn:
        await update.message.reply_text("âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø©.")
        return

    # Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„ÙƒØªØ¨
    books = await conn.fetch("SELECT id, file_id, file_name, uploaded_at FROM books;")

    if not books:
        await update.message.reply_text("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒØªØ¨.")
        return

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ
    query_tokens = tokenize(query)
    titles_tokens = [tokenize(book["file_name"]) for book in books]

    # Ø­Ø³Ø§Ø¨ IDF
    idf = compute_idf(titles_tokens + [query_tokens])

    # Ù…ØªØ¬Ù‡ Ø§Ø³ØªØ¹Ù„Ø§Ù…
    query_vec = compute_tfidf(query_tokens, idf)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    scored_books = []
    for book, tokens in zip(books, titles_tokens):
        book_vec = compute_tfidf(tokens, idf)
        score = cosine_similarity(query_vec, book_vec)
        bd = dict(book)
        bd["score"] = score
        scored_books.append(bd)

    # ÙØ±Ø² Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    scored_books.sort(key=lambda b: (b["score"], b["uploaded_at"]), reverse=True)

    found = any(b["score"] > 0.01 for b in scored_books)

    # Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù
    await notify_admin_search(context, update.effective_user.username, query, found)

    if not found:
        keyboard = InlineKeyboardMarkup([
            [InlineKeyboardButton("ğŸ” Ø¨Ø­Ø« Ù…Ø´Ø§Ø¨Ù‡", callback_data="search_similar")]
        ])
        await update.message.reply_text(
            f"âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù€: {query}", reply_markup=keyboard)
        return

    # Ø­ÙØ¸ ÙˆØ¥Ø±Ø³Ø§Ù„
    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = "ğŸ” Ø¨Ø­Ø« Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (TF-IDF)"

    await send_books_page(update, context)

# -----------------------------
# Ø¨Ø­Ø« Ù…Ø´Ø§Ø¨Ù‡
# -----------------------------

async def search_similar_books(update, context):
    conn = context.bot_data.get("db_conn")
    last_query = context.user_data.get("last_keywords")

    if not conn:
        await update.callback_query.message.reply_text("âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø©.")
        return

    books = await conn.fetch("SELECT id, file_id, file_name, uploaded_at FROM books;")

    titles_tokens = [tokenize(book["file_name"]) for book in books]

    idf = compute_idf(titles_tokens)
    query_vec = compute_tfidf(last_query, idf)

    scored_books = []
    for book, tokens in zip(books, titles_tokens):
        book_vec = compute_tfidf(tokens, idf)
        score = cosine_similarity(query_vec, book_vec)
        bd = dict(book)
        bd["score"] = score
        scored_books.append(bd)

    scored_books.sort(key=lambda b: (b["score"], b["uploaded_at"]), reverse=True)

    if not any(b["score"] > 0.01 for b in scored_books):
        await update.callback_query.message.reply_text("âŒ Ù„Ù… Ø£Ø¬Ø¯ ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø©.")
        return

    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = "ğŸ” Ø¨Ø­Ø« Ù…Ø´Ø§Ø¨Ù‡ (TF-IDF)"

    await send_books_page(update, context)

# -----------------------------
# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ÙƒÙˆÙ„Ø¨Ø§Ùƒ
# -----------------------------

async def handle_callbacks(update, context):
    query = update.callback_query
    await query.answer()
    data = query.data

    if data.startswith("file:"):
        key = data.split(":")[1]
        file_id = context.bot_data.get(f"file_{key}")
        if file_id:
            caption = "ØªÙ… Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© @boooksfree1bot"
            share = InlineKeyboardMarkup([
                [InlineKeyboardButton("ğŸ“¤ Ø´Ø§Ø±Ùƒ Ø§Ù„Ø¨ÙˆØª", switch_inline_query="")]
            ])
            await query.message.reply_document(
                document=file_id, caption=caption, reply_markup=share
            )
        else:
            await query.message.reply_text("âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
    elif data == "next_page":
        context.user_data["current_page"] += 1
        await send_books_page(update, context)
    elif data == "prev_page":
        context.user_data["current_page"] -= 1
        await send_books_page(update, context)
    elif data == "search_similar":
        await search_similar_books(update, context)
