import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List, Dict, Any
import os

BOOKS_PER_PAGE = 10

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±Ù
# -----------------------------
try:
    ADMIN_USER_ID = int(os.getenv("ADMIN_ID", "0"))  # Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø´Ø±Ù
except ValueError:
    ADMIN_USER_ID = 0
    print("âš ï¸ ADMIN_ID environment variable is not valid.")

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------
def normalize_text(text: str) -> str:
    """Ù„ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¨Ø­Ø«."""
    if not text:
        return ""
    text = text.lower()
    text = text.replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ")
    text = text.replace("Ù‡", "Ø©")
    return text

def remove_common_words(text: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø«Ù„ ÙƒØªØ§Ø¨/Ø±ÙˆØ§ÙŠØ©/Ù†Ø³Ø®Ø©."""
    if not text:
        return ""
    for word in ["ÙƒØªØ§Ø¨", "Ø±ÙˆØ§ÙŠØ©", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"]:
        text = text.replace(word, "")
    return text.strip()

def extract_keywords(text: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø© (Ø£Ø·ÙˆÙ„ Ù…Ù† 3 Ø£Ø­Ø±Ù)."""
    if not text:
        return []
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    return [w for w in words if len(w) >= 3]

def get_db_safe_query(normalized_query: str) -> str:
    """Ø¨Ù†Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¢Ù…Ù† Ù…Ù† SQL Injection Ø§Ù„Ø¨Ø³ÙŠØ·."""
    return normalized_query.replace("'", "''")

# -----------------------------
# ØªÙ‚Ø´ÙŠØ± Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª (light stemming)
# -----------------------------
def light_stem(word: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ù„ÙˆØ§Ø­Ù‚ ÙˆØ§Ù„Ù„Ø§Ø­Ù‚Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¬Ø°Ø±."""
    suffixes = ["ÙŠØ©", "ÙŠ", "ÙˆÙ†", "Ø§Øª", "Ø§Ù†", "ÙŠÙ†"]
    for suf in suffixes:
        if word.endswith(suf):
            word = word[:-len(suf)]
            break
    if word.startswith("Ø§Ù„"):
        word = word[2:]
    return word

# -----------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ²Ù†ÙŠ ÙØ§Ø¦Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡
# -----------------------------
def calculate_score(book: Dict[str, Any], keywords: List[str], normalized_query: str) -> int:
    """ÙŠØ­Ø³Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ²Ù†ÙŠ Ù„Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ ÙˆÙ…ÙƒØ§Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø¬Ø°Ø±."""
    score = 0
    book_name = normalize_text(book.get('file_name', ''))

    # Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø±ÙÙŠ Ø§Ù„ÙƒØ§Ù…Ù„
    if normalized_query == book_name:
        score += 50
    # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¬Ù…Ù„Ø©
    elif normalized_query in book_name:
        score += 20

    title_words = book_name.split()
    for k in keywords:
        k_stem = light_stem(k)
        for t_word in title_words:
            t_stem = light_stem(t_word)
            if t_stem.startswith(k_stem):
                score += 10
            elif k_stem in t_stem:
                score += 8
    return score

# -----------------------------
# Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¨Ø­Ø«
# -----------------------------
async def notify_admin_search(context: ContextTypes.DEFAULT_TYPE, username: str, query: str, found: bool):
    """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ù„Ù„Ù…Ø´Ø±Ù Ø¹Ù† Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙŠ Ù‚Ø§Ù… Ø¨Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
    if ADMIN_USER_ID == 0:
        return
    bot = context.bot
    status_text = "âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬" if found else "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬"
    username_text = f"@{username}" if username else "(Ø¨Ø¯ÙˆÙ† ÙŠÙˆØ²Ø±)"
    message = f"ğŸ”” Ù‚Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username_text} Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†:\n`{query}`\nØ§Ù„Ø­Ø§Ù„Ø©: {status_text}"
    try:
        await bot.send_message(ADMIN_USER_ID, message, parse_mode='Markdown')
    except Exception as e:
        print(f"Failed to notify admin: {e}")
