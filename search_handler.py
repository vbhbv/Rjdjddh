import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List, Dict, Any
import os

BOOKS_PER_PAGE = 10

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±Ù
# -----------------------------

try:
    ADMIN_USER_ID = int(os.getenv("ADMIN_ID", "0"))
except ValueError:
    ADMIN_USER_ID = 0
    print("âš ï¸ ADMIN_ID environment variable is not valid.")

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------

def normalize_text(text: str) -> str:
    """Ù„ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¨Ø­Ø«."""
    if not text:
        return ""
    text = text.lower()
    text = text.replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ")
    text = text.replace("Ù‡", "Ø©")
    return text

def remove_common_words(text: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø«Ù„ ÙƒØªØ§Ø¨/Ø±ÙˆØ§ÙŠØ©/Ù†Ø³Ø®Ø©."""
    if not text:
        return ""
    for word in ["ÙƒØªØ§Ø¨", "Ø±ÙˆØ§ÙŠØ©", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"]:
        text = text.replace(word, "")
    return text.strip()

def extract_keywords(text: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø© (Ø£Ø·ÙˆÙ„ Ù…Ù† 3 Ø£Ø­Ø±Ù)."""
    if not text:
        return []
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    return [w for w in words if len(w) >= 3]

def get_db_safe_query(normalized_query: str) -> str:
    """Ø¨Ù†Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¢Ù…Ù† Ù…Ù† SQL Injection Ø§Ù„Ø¨Ø³ÙŠØ·."""
    return normalized_query.replace("'", "''")

# -----------------------------
# ØªÙ‚Ø´ÙŠØ± Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª (light stemming) - Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø¯Ø§Ù„Ø© calculate_score
# -----------------------------

def light_stem(word: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ù„ÙˆØ§Ø­Ù‚ ÙˆØ§Ù„Ù„Ø§Ø­Ù‚Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¬Ø°Ø±."""
    suffixes = ["ÙŠØ©", "ÙŠ", "ÙˆÙ†", "Ø§Øª", "Ø§Ù†", "ÙŠÙ†"]
    for suf in suffixes:
        if word.endswith(suf):
            word = word[:-len(suf)]
            break
    if word.startswith("Ø§Ù„"):
        word = word[2:]
    return word

# -----------------------------
# ğŸ› ï¸ Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ²Ù†ÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙÙ‚Ø·)
# -----------------------------

def calculate_score(book: Dict[str, Any], keywords: List[str], normalized_query: str) -> int:
    """ÙŠØ­Ø³Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ²Ù†ÙŠ Ù„Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ ÙˆÙ…ÙƒØ§Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø¬Ø°Ø±."""
    score = 0
    book_name = normalize_text(book.get('file_name', ''))

    # Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø±ÙÙŠ Ø§Ù„ÙƒØ§Ù…Ù„
    if normalized_query == book_name:
        score += 50
    # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¬Ù…Ù„Ø©
    elif normalized_query in book_name:
        score += 20

    title_words = book_name.split()
    for k in keywords:
        k_stem = light_stem(k)
        for t_word in title_words:
            t_stem = light_stem(t_word)
            if t_stem.startswith(k_stem):
                score += 10
            elif k_stem in t_stem:
                score += 8  # Ø£ÙŠ Ù…ÙƒØ§Ù† ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¬Ø°Ø±
    return score

# -----------------------------
# Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¨Ø­Ø«
# -----------------------------

async def notify_admin_search(context: ContextTypes.DEFAULT_TYPE, username: str, query: str, found: bool):
    """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ù„Ù„Ù…Ø´Ø±Ù Ø¹Ù† Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙŠ Ù‚Ø§Ù… Ø¨Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
    if ADMIN_USER_ID == 0:
        return

    bot = context.bot
    status_text = "âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬" if found else "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬"
    username_text = f"@{username}" if username else "(Ø¨Ø¯ÙˆÙ† ÙŠÙˆØ²Ø±)"
    # ğŸ’¡ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø·Ø±ÙŠÙ‚Ø© ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ Markdown parsing
    message = f"ğŸ”” Ù‚Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username_text} Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}\nØ§Ù„Ø­Ø§Ù„Ø©: {status_text}"
    try:
        await bot.send_message(ADMIN_USER_ID, message) # Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… Markdown Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø®Ø·Ø£ 400
    except Exception as e:
        print(f"Failed to notify admin: {e}")

# -----------------------------
# Ø¥Ø±Ø³Ø§Ù„ ØµÙØ­Ø© Ø§Ù„ÙƒØªØ¨
# -----------------------------

async def send_books_page(update, context: ContextTypes.DEFAULT_TYPE):
    # ğŸ’¡ Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ 'current_page' Ùˆ 'search_stage'
    books = context.user_data.get("search_results", [])
    page = context.user_data.get("current_page", 0)
    search_stage = context.user_data.get("search_stage", "ØªØ·Ø§Ø¨Ù‚ Ø¯Ù‚ÙŠÙ‚")
    total_pages = (len(books) - 1) // BOOKS_PER_PAGE + 1 if books else 1

    start = page * BOOKS_PER_PAGE
    end = start + BOOKS_PER_PAGE
    current_books = books[start:end]

    if "Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ Ù…ÙØ¹Ø²Ø²" in search_stage:
        stage_note = "â­ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø« Ø°ÙƒÙŠØ© ÙˆÙ…ÙØ¹Ø²Ø²Ø© (Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©)"
    else:
        stage_note = "âš ï¸ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹ (Fallback - ØºÙŠØ± Ù…ÙÙÙ‡Ø±Ø³)"

    text = f"ğŸ“š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({len(books)} ÙƒØªØ§Ø¨)\n{stage_note}\nØ§Ù„ØµÙØ­Ø© {page + 1} Ù…Ù† {total_pages}\n\n"
    keyboard = []

    for b in current_books:
        if not b.get("file_name") or not b.get("file_id"):
            continue
        key = hashlib.md5(b["file_id"].encode()).hexdigest()[:16]
        context.bot_data[f"file_{key}"] = b["file_id"]
        keyboard.append([InlineKeyboardButton(f"ğŸ“˜ {b['file_name']}", callback_data=f"file:{key}")])

    nav_buttons = []
    if page > 0:
        nav_buttons.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data="prev_page"))
    if end < len(books):
        nav_buttons.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data="next_page"))
    if nav_buttons:
        keyboard.append(nav_buttons)

    reply_markup = InlineKeyboardMarkup(keyboard)
    if update.message:
        await update.message.reply_text(text, reply_markup=reply_markup)
    elif update.callback_query:
        await update.callback_query.message.edit_text(text, reply_markup=reply_markup)

# -----------------------------
# Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (FTS)
# -----------------------------

async def search_books(update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_chat.type != "private":
        return

    query = update.message.text.strip()
    if not query:
        return

    conn = context.bot_data.get("db_conn")
    if not conn:
        await update.message.reply_text("âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
        return

    normalized_query = normalize_text(remove_common_words(query))
    ts_query_text = get_db_safe_query(normalized_query)
    
    context.user_data["last_query"] = normalized_query
    context.user_data["last_keywords"] = extract_keywords(normalized_query)
    
    books = []
    search_stage_text = "Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ Ù…ÙØ¹Ø²Ø²"

    try:
        # 1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ (FTS)
        books = await conn.fetch("""
            SELECT 
                id, 
                file_id, 
                file_name, 
                uploaded_at,
                ts_rank(file_name_tsvector, plainto_tsquery('arabic', $1)) AS rank_score
            FROM books
            WHERE file_name_tsvector @@ plainto_tsquery('arabic', $1)
            ORDER BY rank_score DESC, uploaded_at DESC
            LIMIT 1000;
        """, ts_query_text)

    except Exception as e:
        # 2. ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ FTS (Ù…Ø«Ù„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯)ØŒ Ù†Ø¹ÙˆØ¯ Ù„Ø®Ø·Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        print(f"FTS Query Failed: {e}. Falling back to old OR search.")
        books = [] # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† books ÙØ§Ø±ØºØ© Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù€ fallback

    found_results = bool(books)
    await notify_admin_search(context, update.effective_user.username, query, found_results)

    if not books:
        # 3. Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ³Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ… (Fallback) ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
        return await search_similar_books(update, context, is_fallback=True)

    # 4. Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù†ØªØ§Ø¦Ø¬ FTS
    scored_books = []
    for book in books:
        book_dict = dict(book)
        book_dict['score'] = book.get('rank_score', 0) 
        scored_books.append(book_dict)

    scored_books.sort(key=lambda b: b['score'], reverse=True)
    
    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = search_stage_text
    await send_books_page(update, context)

# -----------------------------
# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø© (Fallback - ÙŠØ³ØªØ®Ø¯Ù… calculate_score)
# -----------------------------

async def search_similar_books(update, context: ContextTypes.DEFAULT_TYPE, is_fallback=False):
    conn = context.bot_data.get("db_conn")
    query = context.user_data.get("last_query")
    keywords = context.user_data.get("last_keywords")
    
    if not keywords or not conn:
        message_to_edit = update.callback_query.message if update.callback_query else update.message
        await message_to_edit.reply_text("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡.")
        return

    try:
        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ³Ø¹ (OR LIKE) - Ø§Ù„Ù‚Ø¯ÙŠÙ…
        or_conditions = " OR ".join([f"LOWER(file_name) LIKE '%{get_db_safe_query(k)}%'" for k in keywords])
        books = await conn.fetch(f"""
            SELECT id, file_id, file_name, uploaded_at
            FROM books
            WHERE {or_conditions}
            ORDER BY uploaded_at DESC;
        """)
    except Exception as e:
        message_to_edit = update.callback_query.message if update.callback_query else update.message
        await message_to_edit.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ³Ø¹.")
        return

    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© calculate_score Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹Ù‡Ø§
    scored_books = []
    for book in books:
        score = calculate_score(book, keywords, query)
        book_dict = dict(book)
        book_dict['score'] = score
        scored_books.append(book_dict)

    scored_books.sort(key=lambda b: (b['score'], b['uploaded_at']), reverse=True)

    if not scored_books:
        message_to_edit = update.callback_query.message if update.callback_query else update.message
        await message_to_edit.reply_text(f"âŒ Ù„Ù… Ø£Ø¬Ø¯ ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù„Ø¨Ø­Ø«: {query}.")
        return

    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = "Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹ (Fallback)"
    
    await send_books_page(update, context)

# -----------------------------
# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø£Ø²Ø±Ø§Ø± Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
# -----------------------------

async def handle_callbacks(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data

    if data.startswith("file:"):
        key = data.split(":")[1]
        file_id = context.bot_data.get(f"file_{key}")
        if file_id:
            caption = "ØªÙ… Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© @boooksfree1bot"
            share_button = InlineKeyboardMarkup([
                [InlineKeyboardButton("ğŸ“¤ Ø´Ø§Ø±Ùƒ Ø§Ù„Ø¨ÙˆØª Ù…Ø¹ Ø£ØµØ¯Ù‚Ø§Ø¦Ùƒ", switch_inline_query="")]
            ])
            await query.message.reply_document(document=file_id, caption=caption, reply_markup=share_button)
        else:
            await query.message.reply_text("âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")
    elif data == "next_page":
        # ğŸ’¡ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ current_page
        context.user_data["current_page"] = context.user_data.get("current_page", 0) + 1
        await send_books_page(update, context)
    elif data == "prev_page":
        # ğŸ’¡ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ current_page
        context.user_data["current_page"] = context.user_data.get("current_page", 0) - 1
        await send_books_page(update, context)
    elif data == "search_similar":
        await search_similar_books(update, context, is_fallback=True)
