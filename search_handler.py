import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List, Dict, Any
import os
from datetime import datetime

BOOKS_PER_PAGE = 10

# -----------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±Ù
# -----------------------------
try:
    ADMIN_USER_ID = int(os.getenv("ADMIN_ID", "0"))
except ValueError:
    ADMIN_USER_ID = 0
    print("âš ï¸ ADMIN_ID environment variable is not valid.")

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = text.lower().replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ù‡", "Ø©")
    return text

COMMON_WORDS = {"ÙƒØªØ§Ø¨", "Ø±ÙˆØ§ÙŠØ©", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"}

def remove_common_words(text: str) -> str:
    if not text:
        return ""
    words = text.split()
    filtered = [w for w in words if w not in COMMON_WORDS]
    return " ".join(filtered).strip()

def extract_keywords(text: str) -> List[str]:
    if not text:
        return []
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    return [w for w in words if len(w) >= 3]

def get_db_safe_query(normalized_query: str) -> str:
    return normalized_query.replace("'", "''")

# -----------------------------
# ØªÙ‚Ø´ÙŠØ± Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª (light stemming)
# -----------------------------
def light_stem(word: str) -> str:
    suffixes = ["ÙŠØ©", "ÙŠ", "ÙˆÙ†", "Ø§Øª", "Ø§Ù†", "ÙŠÙ†"]
    for suf in suffixes:
        if word.endswith(suf):
            word = word[:-len(suf)]
            break
    if word.startswith("Ø§Ù„"):
        word = word[2:]
    return word

# -----------------------------
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ²Ù†ÙŠ
# -----------------------------
def calculate_score(book: Dict[str, Any], keywords: List[str], normalized_query: str) -> int:
    score = 0
    book_name = normalize_text(book.get('file_name', ''))
    
    # Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø±ÙÙŠ Ø§Ù„ÙƒØ§Ù…Ù„
    if normalized_query == book_name:
        score += 50
    elif normalized_query in book_name:
        score += 20

    # ØªØ·Ø¨ÙŠÙ‚ light_stem Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©
    stemmed_keywords = [light_stem(k) for k in keywords]
    title_words = book_name.split()
    stemmed_title = [light_stem(t) for t in title_words]

    for k_stem in stemmed_keywords:
        for t_stem in stemmed_title:
            if t_stem.startswith(k_stem):
                score += 10
            elif k_stem in t_stem:
                score += 8
    return score

# -----------------------------
# Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¨Ø­Ø«
# -----------------------------
async def notify_admin_search(context: ContextTypes.DEFAULT_TYPE, username: str, query: str, found: bool, results_count: int):
    if ADMIN_USER_ID == 0:
        return
    bot = context.bot
    status_text = "âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬" if found else "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬"
    username_text = f"@{username}" if username else "(Ø¨Ø¯ÙˆÙ† ÙŠÙˆØ²Ø±)"
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    message = f"ğŸ”” Ù‚Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username_text} Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†:\n`{query}`\nØ§Ù„Ø­Ø§Ù„Ø©: {status_text}\nØ¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {results_count}\nØ§Ù„ÙˆÙ‚Øª: {timestamp}"
    try:
        await bot.send_message(ADMIN_USER_ID, message, parse_mode='Markdown')
    except Exception as e:
        print(f"Failed to notify admin: {e}")

# -----------------------------
# Ø¥Ø±Ø³Ø§Ù„ ØµÙØ­Ø© Ø§Ù„ÙƒØªØ¨
# -----------------------------
async def send_books_page(update, context: ContextTypes.DEFAULT_TYPE):
    books = context.user_data.get("search_results", [])
    page = context.user_data.get("current_page", 0)
    total_pages = max((len(books) - 1) // BOOKS_PER_PAGE + 1, 1)
    page = max(0, min(page, total_pages - 1))  # ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¹Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯

    start = page * BOOKS_PER_PAGE
    end = start + BOOKS_PER_PAGE
    current_books = books[start:end]

    stage_note = context.user_data.get("search_stage", "ØªØ·Ø§Ø¨Ù‚ Ø¯Ù‚ÙŠÙ‚")
    if "Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹" in stage_note:
        stage_note = "âš ï¸ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹"
    elif "ØªØ·Ø§Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª" in stage_note:
        stage_note = "âœ… Ù†ØªØ§Ø¦Ø¬ Ø¯Ù„Ø§Ù„ÙŠØ©"
    else:
        stage_note = "âœ… Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©"

    text = f"ğŸ“š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({len(books)} ÙƒØªØ§Ø¨)\n{stage_note}\nØ§Ù„ØµÙØ­Ø© {page + 1} Ù…Ù† {total_pages}\n\n"
    keyboard = []

    for b in current_books:
        if not b.get("file_name") or not b.get("file_id"):
            continue
        key = hashlib.md5(b["file_id"].encode()).hexdigest()[:16]
        context.bot_data[f"file_{key}"] = b["file_id"]
        keyboard.append([InlineKeyboardButton(f"ğŸ“˜ {b['file_name']}", callback_data=f"file:{key}")])

    nav_buttons = []
    if page > 0:
        nav_buttons.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data="prev_page"))
    if end < len(books):
        nav_buttons.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data="next_page"))
    if nav_buttons:
        keyboard.append(nav_buttons)

    reply_markup = InlineKeyboardMarkup(keyboard)
    if update.message:
        await update.message.reply_text(text, reply_markup=reply_markup)
    elif update.callback_query:
        await update.callback_query.message.edit_text(text, reply_markup=reply_markup)
