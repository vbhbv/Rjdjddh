import hashlib
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
import re
from typing import List, Dict, Any

BOOKS_PER_PAGE = 10

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# -----------------------------
def normalize_text(text: str) -> str:
    """Ù„ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¨Ø­Ø«."""
    if not text:
        return ""
    text = text.lower()
    text = text.replace("_", " ")
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙŠØ§Ø¡ ÙˆØ§Ù„Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø©
    text = text.replace("Ù‰", "ÙŠ")
    text = text.replace("Ù‡", "Ø©")
    return text

def remove_common_words(text: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©."""
    if not text:
        return ""
    for word in ["ÙƒØªØ§Ø¨", "Ø±ÙˆØ§ÙŠØ©", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"]:
        text = text.replace(word, "")
    return text.strip()

def extract_keywords(text: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø© (Ø£Ø·ÙˆÙ„ Ù…Ù† 3 Ø£Ø­Ø±Ù)."""
    if not text:
        return []
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
    clean_text = re.sub(r'[^\w\s]', '', text)
    words = clean_text.split()
    # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù…ÙŠØ²Ø© (Ù„Ø£ÙƒØ«Ø± Ù…Ù† 3 Ø­Ø±ÙˆÙ)
    keywords = [w for w in words if len(w) >= 3]
    return keywords

def get_db_safe_query(normalized_query: str) -> str:
    """Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© SQL Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„ØªØ·Ø§Ø¨Ù‚ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    # (Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ÙÙŠØ¯Ø© ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ¯Ø¹Ù… Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©)
    # Ù†Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ù‡Ù†Ø§ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙÙŠ Ø¨Ø§ÙŠØ«ÙˆÙ†
    db_safe_query = normalized_query.replace("'", "''") # Ù„Ù…Ù†Ø¹ SQL Injection Ø§Ù„Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
    return db_safe_query

# -----------------------------
# Ø¥Ø±Ø³Ø§Ù„ ØµÙØ­Ø© Ø§Ù„ÙƒØªØ¨ Ù…Ø¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
# -----------------------------
async def send_books_page(update, context: ContextTypes.DEFAULT_TYPE):
    books = context.user_data.get("search_results", [])
    page = context.user_data.get("current_page", 0)
    search_stage = context.user_data.get("search_stage", "ØªØ·Ø§Ø¨Ù‚ Ø¯Ù‚ÙŠÙ‚")
    total_pages = (len(books) - 1) // BOOKS_PER_PAGE + 1 if books else 1

    start = page * BOOKS_PER_PAGE
    end = start + BOOKS_PER_PAGE
    current_books = books[start:end]

    # Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø°ÙƒÙŠØ©
    if "Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹" in search_stage:
        stage_note = "âš ï¸ **Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹** (Ø¨Ø­Ø«Ù†Ø§ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©)"
    elif "ØªØ·Ø§Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª" in search_stage:
        stage_note = "âœ… **Ù†ØªØ§Ø¦Ø¬ Ø¯Ù„Ø§Ù„ÙŠØ©** (ØªØ·Ø§Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ ÙƒÙ„Ù…Ø§ØªÙƒ)"
    else:
        stage_note = "âœ… **Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©** (ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© ÙƒØ§Ù…Ù„Ø©)"

    text = f"ğŸ“š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({len(books)} ÙƒØªØ§Ø¨)\n{stage_note}\nØ§Ù„ØµÙØ­Ø© {page + 1} Ù…Ù† {total_pages}\n\n"
    keyboard = []

    for b in current_books:
        if not b.get("file_name") or not b.get("file_id"):
            continue
        key = hashlib.md5(b["file_id"].encode()).hexdigest()[:16]
        context.bot_data[f"file_{key}"] = b["file_id"]
        keyboard.append([InlineKeyboardButton(f"ğŸ“˜ {b['file_name']}", callback_data=f"file:{key}")])

    nav_buttons = []
    if page > 0:
        nav_buttons.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data="prev_page"))
    if end < len(books):
        nav_buttons.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data="next_page"))
    if nav_buttons:
        keyboard.append(nav_buttons)

    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø£ÙŠÙ† Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯
    if update.message:
        await update.message.reply_text(text, reply_markup=reply_markup)
    elif update.callback_query:
        # ÙŠÙØ¶Ù„ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ù…Ù† callback_query Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø±Ø¯ Ø¨Ø±Ø³Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©
        await update.callback_query.message.edit_text(text, reply_markup=reply_markup)

# -----------------------------
# Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…Ø±Ø§Ø­Ù„ (MSSA)
# -----------------------------
async def search_books(update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_chat.type != "private":
        return

    query = update.message.text.strip()
    if not query:
        return

    conn = context.bot_data.get("db_conn")
    if not conn:
        await update.message.reply_text("âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
        return

    # 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹
    normalized_query = normalize_text(remove_common_words(query))
    keywords = extract_keywords(normalized_query)
    context.user_data["last_query"] = normalized_query
    context.user_data["last_keywords"] = keywords
    
    books = []
    search_stage_text = "ØªØ·Ø§Ø¨Ù‚ Ø¯Ù‚ÙŠÙ‚"

    try:
        # ------------------------------------------------
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø­Ø±ÙÙŠ Ø§Ù„Ù…ÙØ·Ø¨Ø¹ (Ø§Ù„Ø¯Ù‚Ø© 100%)
        # ------------------------------------------------
        books = await conn.fetch("""
        SELECT id, file_id, file_name, uploaded_at -- ÙŠØ¬Ø¨ Ø¬Ù„Ø¨ uploaded_at Ù„Ù„ØªÙ‚ÙŠÙŠÙ…
        FROM books
        WHERE LOWER(file_name) LIKE '%' || $1 || '%'
        ORDER BY uploaded_at DESC;
        """, normalized_query)

        # ------------------------------------------------
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø´Ø¨Ù‡ Ø¯Ù„Ø§Ù„ÙŠ (Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© - AND)
        # ------------------------------------------------
        if not books and keywords:
            search_stage_text = "ØªØ·Ø§Ø¨Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"
            # Ø¨Ù†Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… AND Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
            and_conditions = " AND ".join([f"LOWER(file_name) LIKE '%{get_db_safe_query(k)}%'" for k in keywords])
            books = await conn.fetch(f"""
            SELECT id, file_id, file_name, uploaded_at
            FROM books
            WHERE {and_conditions}
            ORDER BY uploaded_at DESC;
            """)

        # ------------------------------------------------
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ³Ø¹ (Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© - OR)
        # ------------------------------------------------
        if not books and keywords:
            search_stage_text = "Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
            # Ø¨Ù†Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… OR Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
            or_conditions = " OR ".join([f"LOWER(file_name) LIKE '%{get_db_safe_query(k)}%'" for k in keywords])
            books = await conn.fetch(f"""
            SELECT id, file_id, file_name, uploaded_at
            FROM books
            WHERE {or_conditions}
            ORDER BY uploaded_at DESC;
            """)

    except Exception as e:
        print(f"Database Error: {e}")
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«.")
        return

    if not books:
        keyboard = InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ” Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø©", callback_data="search_similar")]])
        await update.message.reply_text(f"âŒ Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ ÙƒØªØ¨ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø¨Ø­Ø«: {query}\nÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø©:", reply_markup=keyboard)
        context.user_data["search_results"] = []
        context.user_data["current_page"] = 0
        return
    
    # 2. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ (Smart Scoring)
    scored_books = []
    for book in books:
        score = 0
        title_lower = book['file_name'].lower()
        
        # ÙˆØ²Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚: Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
        for k in keywords:
            if k in title_lower:
                score += 1
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¬Ù„ (Record) Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³ (Dict) Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø¶Ø§ÙØ©
        book_dict = dict(book)
        book_dict['score'] = score
        scored_books.append(book_dict)

    # Ø§Ù„ØªØ±ØªÙŠØ¨: Ø£ÙˆÙ„Ø§Ù‹ Ø­Ø³Ø¨ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø£ÙˆÙ„Ø§Ù‹)ØŒ Ø«Ù… Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø±ÙØ¹
    # (Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† uploaded_at Ù‡Ùˆ Ø­Ù‚Ù„ Ø²Ù…Ù†ÙŠ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©)
    scored_books.sort(key=lambda b: (b['score'], b['uploaded_at']), reverse=True)

    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = search_stage_text
    await send_books_page(update, context)

# -----------------------------
# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø© (ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3)
# -----------------------------
async def search_similar_books(update, context: ContextTypes.DEFAULT_TYPE):
    # Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¢Ù† Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3 Ø§Ù„Ù…ÙˆØ³Ø¹Ø© Ù…Ù† Ø§Ù„Ø¨Ø­Ø«
    conn = context.bot_data.get("db_conn")
    keywords = context.user_data.get("last_keywords")
    if not keywords or not conn:
        await update.callback_query.message.reply_text("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡.")
        return
    
    try:
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3 (OR Conditions) Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
        or_conditions = " OR ".join([f"LOWER(file_name) LIKE '%{get_db_safe_query(k)}%'" for k in keywords])
        books = await conn.fetch(f"""
        SELECT id, file_id, file_name, uploaded_at
        FROM books
        WHERE {or_conditions}
        ORDER BY uploaded_at DESC;
        """)
    except Exception as e:
        await update.callback_query.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø©.")
        return

    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
    scored_books = []
    for book in books:
        score = 0
        title_lower = book['file_name'].lower()
        for k in keywords:
            if k in title_lower:
                score += 1
        book_dict = dict(book)
        book_dict['score'] = score
        scored_books.append(book_dict)
    
    scored_books.sort(key=lambda b: (b['score'], b['uploaded_at']), reverse=True)


    if not scored_books:
        await update.callback_query.message.reply_text("âŒ Ù„Ù… Ø£Ø¬Ø¯ ÙƒØªØ¨ Ù…Ø´Ø§Ø¨Ù‡Ø©.")
        return

    context.user_data["search_results"] = scored_books
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = "Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹ (Ù…Ø´Ø§Ø¨Ù‡)" # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±Ø­Ù„Ø©
    await send_books_page(update, context)


# -----------------------------
# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø£Ø²Ø±Ø§Ø± Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
# -----------------------------
async def handle_callbacks(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data

    if data.startswith("file:"):
        key = data.split(":")[1]
        file_id = context.bot_data.get(f"file_{key}")
        if file_id:
            caption = "ØªÙ… Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© [Ø§Ø³Ù… Ø§Ù„Ø¨ÙˆØª Ù‡Ù†Ø§]"
            share_button = InlineKeyboardMarkup([
                # ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙØ§Ø±ØºØ© Ø¨Ø§Ø³Ù… Ø§Ù„Ø¨ÙˆØª Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
                [InlineKeyboardButton("ğŸ“¤ Ø´Ø§Ø±Ùƒ Ø§Ù„Ø¨ÙˆØª Ù…Ø¹ Ø£ØµØ¯Ù‚Ø§Ø¦Ùƒ", switch_inline_query="")] 
            ])
            await query.message.reply_document(document=file_id, caption=caption, reply_markup=share_button)
        else:
            await query.message.reply_text("âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")
    elif data == "next_page":
        context.user_data["current_page"] += 1
        await send_books_page(update, context)
    elif data == "prev_page":
        context.user_data["current_page"] -= 1
        await send_books_page(update, context)
    elif data == "search_similar":
        await search_similar_books(update, context)

