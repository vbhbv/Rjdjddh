import re
import logging
from typing import List
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)

BOOKS_PER_PAGE = 10
MAX_RESULTS = 500

# -----------------------------
# Ø§Ù„ØªØ·Ø¨ÙŠØ¹
# -----------------------------
def normalize_query(text: str) -> str:
    if not text:
        return ""
    text = text.lower().strip()
    repls = str.maketrans("Ø£Ø¥Ø¢Ø©Ù‰", "Ø§Ø§Ø§ÙˆÙ‡")
    text = text.translate(repls)
    text = re.sub(r"[Ù‹ÙŒÙÙÙÙÙ’Ù‘Ù€]", "", text)
    text = re.sub(r"[^\w\s]", " ", text)
    return " ".join(text.split())

def get_clean_keywords(text: str) -> List[str]:
    stop_words = {"Ø±ÙˆØ§ÙŠØ©", "ØªØ­Ù…ÙŠÙ„", "ÙƒØªØ§Ø¨", "Ù…Ø¬Ø§Ù†ÙŠ", "pdf", "Ù†Ø³Ø®Ø©", "Ø§Ø±ÙŠØ¯"}
    words = text.split()
    if len(words) <= 2:
        return words
    return [w for w in words if w not in stop_words]

# -----------------------------
# Ø§Ù„Ø¨Ø­Ø«
# -----------------------------
async def search_books(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text.strip()
    conn = context.bot_data.get("db_conn")

    if not conn:
        await update.message.reply_text("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return

    norm_q = normalize_query(query)
    keywords = get_clean_keywords(norm_q)

    ts_and = " & ".join([f"{w}:*" for w in keywords])
    ts_or = " | ".join([f"{w}:*" for w in keywords])
    full_pattern = f"%{norm_q}%"

    try:
        sql = """
        WITH candidates AS (
            SELECT id, file_id, file_name
            FROM books
            WHERE
                to_tsvector('arabic', file_name) @@ to_tsquery('arabic', $1)
                OR file_name ILIKE $2
                OR file_name % $3
            LIMIT 1000
        )
        SELECT id, file_id, file_name,
               ts_rank_cd(to_tsvector('arabic', file_name), to_tsquery('arabic', $1)) AS rank,
               similarity(file_name, $3) AS sim
        FROM candidates
        ORDER BY
            (file_name ILIKE $2) DESC,
            rank DESC,
            sim DESC
        LIMIT $4;
        """

        rows = await conn.fetch(sql, ts_and, full_pattern, norm_q, MAX_RESULTS)

        if not rows:
            rows = await conn.fetch(sql, ts_or, full_pattern, norm_q, MAX_RESULTS)

        if not rows:
            from search_suggestions import send_search_suggestions
            context.user_data["last_query"] = query
            await send_search_suggestions(update, context)
            return

        context.user_data["search_results"] = [dict(r) for r in rows]
        context.user_data["current_page"] = 0
        await send_books_page(update, context)

    except Exception as e:
        logger.error(f"Search error: {e}")
        await update.message.reply_text("âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«.")

# -----------------------------
# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# -----------------------------
async def send_books_page(update, context: ContextTypes.DEFAULT_TYPE):
    results = context.user_data.get("search_results", [])
    page = context.user_data.get("current_page", 0)

    start = page * BOOKS_PER_PAGE
    end = start + BOOKS_PER_PAGE
    batch = results[start:end]
    total_pages = (len(results) - 1) // BOOKS_PER_PAGE + 1

    text = f"ğŸ“š **Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« ({len(results)} Ù†ØªÙŠØ¬Ø©)**\n"
    text += f"Ø§Ù„ØµÙØ­Ø© {page + 1} Ù…Ù† {total_pages}\n\n"

    keyboard = []
    for b in batch:
        name = b["file_name"]
        name = name if len(name) < 48 else name[:45] + ".."
        keyboard.append([
            InlineKeyboardButton(
                f"ğŸ“– {name}",
                callback_data=f"file:{b['id']}"
            )
        ])

    nav = []
    if page > 0:
        nav.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data="prev_page"))
    if end < len(results):
        nav.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data="next_page"))
    if nav:
        keyboard.append(nav)

    markup = InlineKeyboardMarkup(keyboard)

    if update.message:
        await update.message.reply_text(text, reply_markup=markup, parse_mode="Markdown")
    else:
        await update.callback_query.message.edit_text(text, reply_markup=markup, parse_mode="Markdown")

# -----------------------------
# callbacks (Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‚ØªØ¨Ø³ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
# -----------------------------
async def handle_callbacks(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    data = query.data
    conn = context.bot_data.get("db_conn")

    await query.answer()  # âœ… Ù†ÙØ³ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø­Ø±ÙÙŠÙ‹Ø§

    if data.startswith("file:"):
        book_id = int(data.split(":")[1])
        row = await conn.fetchrow(
            "SELECT file_id, file_name FROM books WHERE id = $1",
            book_id
        )

        if row:
            try:
                await query.message.reply_document(
                    document=row["file_id"],
                    caption="ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨ Ø¨ÙˆØ§Ø³Ø·Ø© @boooksfree1bot",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ“¤ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¨ÙˆØª", switch_inline_query="")]
                    ])
                )
            except Exception as e:
                logger.error(f"Download error: {e}")
                await query.message.reply_text("âŒ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù.")
        else:
            await query.message.reply_text("âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")

    elif data == "next_page":
        context.user_data["current_page"] += 1
        await send_books_page(update, context)

    elif data == "prev_page":
        context.user_data["current_page"] -= 1
        await send_books_page(update, context)
