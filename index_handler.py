import re
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from search_handler import send_books_page  # Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Ø§Ù„ÙƒØªØ¨

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„Ù†Ø¸Ø§ÙØ©
# -----------------------------
def normalize_text(text: str) -> str:
    if not text: return ""
    text = text.lower()
    text = text.replace("_", " ")
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ù‡", "Ø©")
    return text

def remove_common_words(text: str) -> str:
    if not text: return ""
    for word in ["ÙƒØªØ§Ø¨", "Ù†Ø³Ø®Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø¬Ù„Ø¯", "Ø¬Ø²Ø¡"]:
        text = text.replace(word, "")
    return text.strip()

# -----------------------------
# Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Ø¯ÙˆÙ† Ø£ÙŠ ØªØºÙŠÙŠØ±)
# -----------------------------
INDEXES_AR = [
    ("Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª", "novels", ["Ø±ÙˆØ§ÙŠØ©"]),
    ("Ù‚ØµØµ Ø§Ù„Ø£Ø·ÙØ§Ù„", "children_stories", ["Ù‚ØµØµ", "Ø£Ø·ÙØ§Ù„", "Ø­ÙƒØ§ÙŠØ©", "Ù…ØºØ§Ù…Ø±Ø©"]),
    ("Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "arabic_grammar", ["Ù‚ÙˆØ§Ø¹Ø¯", "Ù†Ø­Ùˆ", "ØµØ±Ù"]),
    ("Ø§Ù„Ø´Ø¹Ø±", "poetry", ["Ø´Ø§Ø¹Ø±", "Ù‚ØµÙŠØ¯Ø©", "Ø¯ÙŠÙˆØ§Ù†"]),
    ("Ø§Ù„Ù†Ù‚Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠ", "literary_criticism", ["Ù†Ù‚Ø¯", "ØªØ­Ù„ÙŠÙ„", "Ø£Ø¯Ø¨"]),
    ("Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡", "physics", ["ÙÙŠØ²ÙŠØ§Ø¡", "Ø·Ø§Ù‚Ø©", "Ù…ÙŠÙƒØ§Ù†ÙŠÙƒØ§"]),
    ("Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡", "chemistry", ["ÙƒÙŠÙ…ÙŠØ§Ø¡", "ØªÙØ§Ø¹Ù„", "Ø¹Ù†ØµØ±"]),
    ("Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "math", ["Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø¬Ø¨Ø±", "Ù‡Ù†Ø¯Ø³Ø©"]),
    ("Ø§Ù„ÙÙ„Ø³ÙØ©", "philosophy", ["ÙÙ„Ø³ÙØ©", "Ù…Ù†Ø·Ù‚", "Ø£Ø®Ù„Ø§Ù‚"]),
    ("Ø¹Ù„Ù… Ø§Ù„Ù†ÙØ³", "psychology", ["Ø¹Ù„Ù… Ø§Ù„Ù†ÙØ³", "Ø³Ù„ÙˆÙƒ", "Ø¹Ù‚Ù„"]),
    ("Ø¹Ù„Ù… Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹", "sociology", ["Ø¹Ù„Ù… Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹", "Ù…Ø¬ØªÙ…Ø¹", "Ø«Ù‚Ø§ÙØ©"]),
    ("Ø§Ù„ØªØ§Ø±ÙŠØ®", "history", ["ØªØ§Ø±ÙŠØ®", "Ø­Ø¶Ø§Ø±Ø©", "Ø¹ØµÙˆØ±"]),
    ("Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ§", "geography", ["Ø¬ØºØ±Ø§ÙÙŠØ§", "Ø®Ø±Ø§Ø¦Ø·", "Ù…Ù†Ø§Ø®"]),
    ("Ø§Ù„Ø³ÙŠØ§Ø³Ø©", "politics", ["Ø³ÙŠØ§Ø³Ø©", "Ø­ÙƒÙˆÙ…Ø©", "Ø¯ÙˆÙ„Ø©"]),
    ("Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯", "economics", ["Ø§Ù‚ØªØµØ§Ø¯", "Ù…Ø§Ù„", "ØªØ¬Ø§Ø±Ø©"]),
    ("Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©", "programming", ["Ø¨Ø±Ù…Ø¬Ø©", "python", "java"]),
    ("Ø§Ù„Ù‡Ù†Ø¯Ø³Ø©", "engineering", ["Ù‡Ù†Ø¯Ø³Ø©", "Ù…ÙŠÙƒØ§Ù†ÙŠÙƒØ§", "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"]),
    ("Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§", "technology", ["ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø±ÙˆØ¨ÙˆØª"]),
    ("Ø§Ù„ØªØ¹Ù„ÙŠÙ…", "education", ["ØªØ¹Ù„ÙŠÙ…", "Ù…Ø¯Ø±Ø³Ø©", "Ø¬Ø§Ù…Ø¹Ø©"]),
    ("Ø§Ù„Ù„ØºØ§Øª", "languages", ["Ù„ØºØ©", "ØªØ±Ø¬Ù…Ø©", "Ù‚Ø§Ù…ÙˆØ³"]),
    ("Ø§Ù„Ø·Ø¨", "medicine", ["Ø·Ø¨", "Ø¯ÙˆØ§Ø¡", "Ø¹Ù„Ø§Ø¬"]),
    ("ØµÙŠØ¯Ù„Ø©", "pharmacy", ["ØµÙŠØ¯Ù„Ø©", "Ø¯ÙˆØ§Ø¡"]),
    ("Ø·Ø¨ Ø£Ø³Ù†Ø§Ù†", "dentistry", ["Ø£Ø³Ù†Ø§Ù†", "ØªÙ‚ÙˆÙŠÙ…"]),
    ("Ø£Ø¹Ø´Ø§Ø¨ Ø·Ø¨ÙŠØ¹ÙŠØ©", "herbal_medicine", ["Ø£Ø¹Ø´Ø§Ø¨", "Ø·Ø¨ÙŠØ¹ÙŠØ©"]),
    ("Ø¨Ù‡Ø§Ø±Ø§Øª", "spices", ["Ø¨Ù‡Ø§Ø±Ø§Øª", "ØªÙˆØ§Ø¨Ù„"]),
    ("Ø§Ù„Ø·Ø¨Ø®", "cooking", ["Ø·Ø¨Ø®", "ÙˆØµÙØ§Øª", "Ù…Ø·Ø¨Ø®"]),
    ("Ø§Ù„Ø³ÙØ±", "travel", ["Ø³ÙØ±", "Ø±Ø­Ù„Ø©", "Ø³ÙŠØ§Ø­Ø©"]),
    ("Ø§Ù„ÙÙ†ÙˆÙ†", "arts", ["ÙÙ†", "Ø±Ø³Ù…", "Ù…ÙˆØ³ÙŠÙ‚Ù‰"]),
    ("Ø§Ù„ØªØµÙ…ÙŠÙ…", "design", ["ØªØµÙ…ÙŠÙ…", "Ø§Ø¨Ø¯Ø§Ø¹", "Ø§Ø¨ØªÙƒØ§Ø±"]),
    ("Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ", "interior_design", ["ØªØµÙ…ÙŠÙ… Ø¯Ø§Ø®Ù„ÙŠ", "Ø¯ÙŠÙƒÙˆØ±"]),
    ("Ø§Ù„Ø¯ÙŠÙƒÙˆØ±", "decor", ["Ø¯ÙŠÙƒÙˆØ±", "ØªØ²ÙŠÙŠÙ†", "Ø¥Ø¶Ø§Ø¡Ø©"]),
    ("Ø§Ù„Ø¯ÙŠÙ†", "religion", ["Ø¯ÙŠÙ†", "Ø§Ø³Ù„Ø§Ù…", "Ù…Ø³ÙŠØ­ÙŠØ©"]),
    ("Ø§Ù„Ø±ÙŠØ§Ø¶Ø©", "sports", ["Ø±ÙŠØ§Ø¶Ø©", "ÙƒØ±Ø©", "ØªÙ…Ø§Ø±ÙŠÙ†"]),
    ("Ø§Ù„Ø£Ø³Ø§Ø·ÙŠØ±", "mythology", ["Ø£Ø³Ø·ÙˆØ±Ø©", "Ø®Ø±Ø§ÙØ©"]),
    ("Ø§Ù„Ø£Ø¨Ø±Ø§Ø¬", "horoscopes", ["Ø¨Ø±Ø¬", "ÙÙ„Ùƒ"]),
    ("Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ", "astronomy", ["ÙÙ„Ùƒ", "Ù†Ø¬ÙˆÙ…"]),
    ("Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©", "mental_health", ["Ø¹Ù‚Ù„", "Ø±Ø§Ø­Ø©"]),
    ("Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰", "music", ["Ù…ÙˆØ³ÙŠÙ‚Ù‰", "Ø¢Ù„Ø©"]),
    ("Ø§Ù„Ø±Ø³Ù…", "drawing", ["Ø±Ø³Ù…", "Ù„ÙˆØ­Ø©"]),
    ("Ø§Ù„Ø³ÙŠÙ†Ù…Ø§", "cinema", ["ÙÙŠÙ„Ù…", "Ø¹Ø±Ø¶"]),
    ("Ø§Ù„ØªØµÙˆÙŠØ± Ø§Ù„ÙÙˆØªÙˆØºØ±Ø§ÙÙŠ", "photography", ["ØªØµÙˆÙŠØ±", "ÙƒØ§Ù…ÙŠØ±Ø§"]),
    ("Ø§Ù„Ø¹Ø·ÙˆØ±", "perfumes", ["Ø¹Ø·ÙˆØ±", "Ø±ÙˆØ§Ø¦Ø­", "Ø³Ø­Ø±"]),
    ("Ø§Ù„Ø³Ù…ÙˆÙ…", "toxins", ["Ø³Ù…ÙˆÙ…", "Ù…ÙˆØ§Ø¯ Ø®Ø·Ø±Ø©", "ÙƒÙŠÙ…ÙŠØ§Ø¡"])
]

# -----------------------------
# Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
# -----------------------------
INDEXES_EN = [
    ("Novels", "novels_en", ["novel"]),
    ("Children Stories", "children_stories_en", ["children", "story"]),
    ("Arabic Grammar", "arabic_grammar_en", ["grammar", "arabic"]),
    ("Poetry", "poetry_en", ["poem", "poetry"]),
    ("Literary Criticism", "literary_criticism_en", ["criticism", "literature"]),
    ("Physics", "physics_en", ["physics", "mechanics"]),
    ("Chemistry", "chemistry_en", ["chemistry", "reaction"]),
    ("Mathematics", "math_en", ["math", "algebra", "geometry"]),
    ("Philosophy", "philosophy_en", ["philosophy", "logic"]),
    ("Psychology", "psychology_en", ["psychology", "behavior"]),
    ("Sociology", "sociology_en", ["sociology", "society"]),
    ("History", "history_en", ["history", "civilization"]),
    ("Geography", "geography_en", ["geography", "maps"]),
    ("Politics", "politics_en", ["politics", "government"]),
    ("Economics", "economics_en", ["economics", "finance"]),
    ("Programming", "programming_en", ["programming", "python", "java"]),
    ("Engineering", "engineering_en", ["engineering", "mechanics"]),
    ("Technology", "technology_en", ["technology", "AI", "robot"]),
    ("Education", "education_en", ["education", "school", "university"]),
    ("Languages", "languages_en", ["language", "dictionary", "translation"]),
    ("Medicine", "medicine_en", ["medicine", "treatment"]),
    ("Pharmacy", "pharmacy_en", ["pharmacy", "medicine"]),
    ("Dentistry", "dentistry_en", ["dentistry", "teeth"]),
    ("Herbal Medicine", "herbal_medicine_en", ["herbal", "natural"]),
    ("Spices", "spices_en", ["spices", "flavor"]),
    ("Cooking", "cooking_en", ["cooking", "recipe"]),
    ("Travel", "travel_en", ["travel", "trip"]),
    ("Arts", "arts_en", ["art", "painting", "music"]),
    ("Design", "design_en", ["design", "creative"]),
    ("Interior Design", "interior_design_en", ["interior", "decoration"]),
    ("Decor", "decor_en", ["decor", "lighting"]),
    ("Religion", "religion_en", ["religion", "islam", "christian"]),
    ("Sports", "sports_en", ["sports", "football"]),
    ("Mythology", "mythology_en", ["myth", "legend"]),
    ("Horoscopes", "horoscopes_en", ["horoscope", "zodiac"]),
    ("Astronomy", "astronomy_en", ["astronomy", "stars"]),
    ("Mental Health", "mental_health_en", ["mental", "health"]),
    ("Music", "music_en", ["music", "instrument"]),
    ("Drawing", "drawing_en", ["drawing", "art"]),
    ("Cinema", "cinema_en", ["film", "movie"]),
    ("Photography", "photography_en", ["photography", "camera"]),
    ("Perfumes", "perfumes_en", ["perfumes", "fragrance"]),
    ("Toxins", "toxins_en", ["toxins", "danger"])
]

INDEXES_PER_PAGE = 10

# -----------------------------
# Ø¹Ø±Ø¶ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¨ØµÙØ­Ø§Øª (Ø¹Ø§Ù… Ù„ÙƒÙ„ ÙÙ‡Ø±Ø³)
# -----------------------------
async def show_index_page(update, context: ContextTypes.DEFAULT_TYPE, indexes, page: int = 0):
    start = page * INDEXES_PER_PAGE
    end = start + INDEXES_PER_PAGE
    current_indexes = indexes[start:end]
    total_indexes = len(indexes)

    keyboard = [[InlineKeyboardButton(name, callback_data=f"index:{key}")] for name, key, _ in current_indexes]

    nav_buttons = []
    if page > 0:
        nav_buttons.append(InlineKeyboardButton("â¬…ï¸ Ø§Ù„Ø³Ø§Ø¨Ù‚", callback_data=f"index_page:{page}"))
    if end < len(indexes):
        nav_buttons.append(InlineKeyboardButton("Ø§Ù„ØªØ§Ù„ÙŠ â¡ï¸", callback_data=f"index_page:{page+1}"))
    if nav_buttons:
        keyboard.append(nav_buttons)

    reply_markup = InlineKeyboardMarkup(keyboard)
    text = f"ğŸ“š Ø§Ø®ØªØ± Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ¹Ø±Ø§Ø¶Ù‡ (Ø¹Ø¯Ø¯ Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {total_indexes}):"
    if update.callback_query:
        await update.callback_query.message.edit_text(text, reply_markup=reply_markup)
        await update.callback_query.answer()
    elif update.message:
        await update.message.reply_text(text, reply_markup=reply_markup)

# -----------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
# -----------------------------
async def show_index(update, context: ContextTypes.DEFAULT_TYPE, page: int = 0):
    await show_index_page(update, context, INDEXES_AR, page)

async def show_index_en(update, context: ContextTypes.DEFAULT_TYPE, page: int = 0):
    await show_index_page(update, context, INDEXES_EN, page)

# -----------------------------
# Ø§Ù„Ù…Ù„Ø§Ø­Ø© Ø¨ÙŠÙ† ØµÙØ­Ø§Øª Ø§Ù„ÙÙ‡Ø±Ø³
# -----------------------------
async def navigate_index_pages(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    try:
        page = int(query.data.split(":")[1])
    except Exception:
        await query.message.reply_text("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØµÙØ­Ø©.")
        return

    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù† user_data
    current_index_type = context.user_data.get("current_index_type", "ar")
    if current_index_type == "en":
        await show_index_en(update, context, page)
    else:
        await show_index(update, context, page)

# -----------------------------
# Ø§Ù„Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‡Ø±Ø³ ÙˆØ¹Ø±Ø¶ Ø§Ù„ÙƒØªØ¨
# -----------------------------
async def search_by_index(update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    index_key = query.data.replace("index:", "")

    conn = context.bot_data.get("db_conn")
    if not conn:
        await query.message.reply_text("âŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØµÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
        return

    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ÙÙ‡Ø±Ø³
    if any(key == index_key for _, key, _ in INDEXES_EN):
        keywords_list = INDEXES_EN
        context.user_data["current_index_type"] = "en"
    else:
        keywords_list = INDEXES_AR
        context.user_data["current_index_type"] = "ar"

    keywords = []
    for name, key, kws in keywords_list:
        if key == index_key:
            keywords = kws
            break

    if not keywords:
        await query.message.reply_text("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„ÙÙ‡Ø±Ø³.")
        return

    keywords = [normalize_text(remove_common_words(k)) for k in keywords]

    # ØµØ§Ø±Ù… Ù„Ù„Ø±ÙˆØ§ÙŠØ§Øª ÙÙ‚Ø·
    if index_key in ["novels", "novels_en"]:
        sql_condition = " AND ".join([f"LOWER(file_name) LIKE '%{k}%'" for k in keywords])
    else:
        sql_condition = " OR ".join([f"LOWER(file_name) LIKE '%{k}%'" for k in keywords])

    try:
        books = await conn.fetch(f"""
            SELECT id, file_id, file_name, uploaded_at
            FROM books
            WHERE {sql_condition}
            ORDER BY uploaded_at DESC;
        """)
    except Exception:
        await query.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒØªØ¨.")
        return

    if not books:
        await query.message.reply_text("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ÙƒØªØ¨ Ø¶Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„ÙÙ‡Ø±Ø³.")
        return

    context.user_data["search_results"] = [dict(b) for b in books]
    context.user_data["current_page"] = 0
    context.user_data["search_stage"] = f"ÙÙ‡Ø±Ø³: {index_key}"
    context.user_data["is_index"] = True
    context.user_data["index_key"] = index_key

    # Ø²Ø± Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„ÙÙ‡Ø±Ø³ Ø«Ø§Ø¨Øª Ù„Ø¬Ù…ÙŠØ¹ ØµÙØ­Ø§Øª Ø§Ù„ÙƒØªØ¨
    await send_books_page(update, context, include_index_home=True)
